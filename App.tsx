import React, { useState, useEffect, useRef } from 'react';
import { GoogleGenerativeAI } from '@google/generative-ai';
import { Tab, Tabs, TabList, TabPanel } from 'react-tabs';
import 'react-tabs/style/react-tabs.css';
import ReactMarkdown from 'react-markdown';

// â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼
// â˜…ã‚ãªãŸã®æ–°ã—ã„å®‰å…¨ãªAPIã‚­ãƒ¼ã‚’ã“ã“ã«è¨­å®šã—ã¦ãã ã•ã„
const API_KEY = import.meta.env.VITE_GEMINI_API_KEY;
// â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²

const genAI = new GoogleGenerativeAI(API_KEY);
const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash-preview-05-20" });

// â˜…â˜…â˜…â˜…â˜… è¿½åŠ ï¼šã‚¯ãƒ©ãƒƒã‚·ãƒ¥å¾©æ—§ã®ãŸã‚ã®IndexedDBæ“ä½œãƒ˜ãƒ«ãƒ‘ãƒ¼ â˜…â˜…â˜…â˜…â˜…
const dbManager = {
    dbName: 'TranscriptionDB',
    storeName: 'audioChunks',
    db: null as IDBDatabase | null,

    openDB(): Promise<IDBDatabase> {
        return new Promise((resolve, reject) => {
            // æ—¢ã«DBã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒã‚ã‚Œã°å†åˆ©ç”¨
            if (this.db) {
                resolve(this.db);
                return;
            }
            const request = indexedDB.open(this.dbName, 1);
            request.onerror = () => reject("IndexedDBã®ã‚ªãƒ¼ãƒ—ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸ");
            request.onsuccess = () => {
                this.db = request.result;
                resolve(this.db);
            };
            request.onupgradeneeded = (event) => {
                const db = (event.target as IDBOpenDBRequest).result;
                if (!db.objectStoreNames.contains(this.storeName)) {
                    db.createObjectStore(this.storeName, { autoIncrement: true });
                }
            };
        });
    },

    async addAudioChunk(chunk: Blob) {
        const db = await this.openDB();
        const transaction = db.transaction(this.storeName, 'readwrite');
        const store = transaction.objectStore(this.storeName);
        store.add(chunk);
        return new Promise<void>((resolve, reject) => {
            transaction.oncomplete = () => resolve();
            transaction.onerror = (event) => reject(`ãƒãƒ£ãƒ³ã‚¯ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: ${event.target?.['error']}`);
        });
    },

    async getAllAudioChunks(): Promise<Blob[]> {
        const db = await this.openDB();
        const transaction = db.transaction(this.storeName, 'readonly');
        const store = transaction.objectStore(this.storeName);
        const request = store.getAll();
        return new Promise((resolve, reject) => {
            request.onsuccess = () => resolve(request.result);
            request.onerror = (event) => reject(`ãƒãƒ£ãƒ³ã‚¯ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: ${event.target?.['error']}`);
        });
    },

    async clearAudioChunks() {
        const db = await this.openDB();
        const transaction = db.transaction(this.storeName, 'readwrite');
        const store = transaction.objectStore(this.storeName);
        store.clear();
        return new Promise<void>((resolve, reject) => {
            transaction.oncomplete = () => resolve();
            transaction.onerror = (event) => reject(`ãƒãƒ£ãƒ³ã‚¯ã®ã‚¯ãƒªã‚¢ã«å¤±æ•—ã—ã¾ã—ãŸ: ${event.target?.['error']}`);
        });
    }
};


// éŸ³å£°Blobã‚’Base64æ–‡å­—åˆ—ã«å¤‰æ›ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
const blobToBase64 = (blob: Blob): Promise<string> => {
    return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onloadend = () => {
            const base64data = reader.result as string;
            resolve(base64data.split(',')[1]);
        };
        reader.onerror = reject;
        reader.readAsDataURL(blob);
    });
};

// éŒ²éŸ³ä¸­ãƒ»æ¸…æ›¸ç”¨ã®AIé–¢æ•°
const transcribeAndIdentifySpeakers = async (audioChunk: Blob, memo: string) => {
    try {
        const audioBase64 = await blobToBase64(audioChunk);
        const prompt = `ã‚ãªãŸã¯éå¸¸ã«å„ªç§€ãªAIè­°äº‹éŒ²ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã€‘ã‚’æœ€å¤§ã®ãƒ’ãƒ³ãƒˆã¨ã—ã¦æ´»ç”¨ã—ã€æä¾›ã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è©±è€…ã‚’ç‰¹å®šã—ã€æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ã€‚

ã€åˆ¶ç´„ã€‘
- ç™ºè¨€è€…ã”ã¨ã«æ”¹è¡Œã—ã¦ãã ã•ã„ã€‚
- å„ç™ºè¨€ã®å‰ã«ã€è©±ã—ã¦ã„ã‚‹äººç‰©åã‚’[åå‰]ã®å½¢å¼ã§ä»˜ã‘ã¦ãã ã•ã„ã€‚åå‰ãŒä¸æ˜ãªå ´åˆã¯[ä¸æ˜]ã¨è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚
- éŸ³å£°ã®å†…å®¹ã‚’å¿ å®Ÿã«æ–‡å­—ã«èµ·ã“ã—ã¦ãã ã•ã„ã€‚è¦ç´„ã¯ã—ãªã„ã§ãã ã•ã„ã€‚
- å‡ºåŠ›ã¯æ–‡å­—èµ·ã“ã—ã®çµæœã®ã¿ã¨ã—ã€ãã‚Œä»¥å¤–ã®æ–‡ç« ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚

ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã€‘
${memo ? memo : 'ãªã—'}

ä»¥ä¸Šã®æŒ‡ç¤ºã«å¾“ã£ã¦ã€ä»¥ä¸‹ã®éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ã€‚`;

        const result = await model.generateContent([ prompt, { inlineData: { mimeType: 'audio/wav', data: audioBase64 } } ]);
        const text = result.response.text();
        return (!text || text.trim() === '') ? 'ï¼ˆç„¡éŸ³ã¾ãŸã¯èªè­˜ä¸èƒ½åŒºé–“ï¼‰' : text;
    } catch (error) {
        console.error("è©±è€…ç‰¹å®šä»˜ãæ–‡å­—èµ·ã“ã—ä¸­ã«ã‚¨ãƒ©ãƒ¼:", error);
        throw error;
    }
};

// ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®åˆæœŸæ–‡å­—èµ·ã“ã—ç”¨ã®AIé–¢æ•°
const transcribeFileRaw = async (audioChunk: Blob) => {
    try {
        const audioBase64 = await blobToBase64(audioChunk);
        const prompt = `ä»¥ä¸‹ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æ—¥æœ¬èªã§æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ã€‚è©±è€…ç‰¹å®šã®å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å¥èª­ç‚¹ã®ã¿é©åˆ‡ã«ä»˜ä¸ã—ã¦ãã ã•ã„ã€‚`;
        const result = await model.generateContent([ prompt, { inlineData: { mimeType: 'audio/wav', data: audioBase64 } } ]);
        const text = result.response.text();
        return (!text || text.trim() === '') ? 'ï¼ˆç„¡éŸ³ã¾ãŸã¯èªè­˜ä¸èƒ½åŒºé–“ï¼‰' : text;
    } catch (error) {
        console.error("ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®åˆæœŸæ–‡å­—èµ·ã“ã—ä¸­ã«ã‚¨ãƒ©ãƒ¼:", error);
        throw error;
    }
};

// AIã«ã‚ˆã‚‹æ¸…æ›¸ç”¨ã®é–¢æ•°
const refineTranscriptWithMemo = async (rawTranscript: string, memo: string) => {
     try {
        const prompt = `ã‚ãªãŸã¯éå¸¸ã«å„ªç§€ãªAIç·¨é›†è€…ã§ã™ã€‚
ä»¥ä¸‹ã®ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã€‘ã¨ã€å…ƒã®æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã€‘ã‚’å…ƒã«ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¸…æ›¸ã—ã¦ãã ã•ã„ã€‚

ã€æ¸…æ›¸ãƒ«ãƒ¼ãƒ«ã€‘
- ç™ºè¨€è€…ã”ã¨ã«æ”¹è¡Œã—ã¦ãã ã•ã„ã€‚
- å„ç™ºè¨€ã®å‰ã«ã€è©±ã—ã¦ã„ã‚‹äººç‰©åã‚’[åå‰]ã®å½¢å¼ã§ä»˜ã‘ã¦ãã ã•ã„ã€‚åå‰ãŒä¸æ˜ãªå ´åˆã¯[ä¸æ˜]ã¨è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚
- èª¤å­—è„±å­—ã‚„ã€æ˜ã‚‰ã‹ãªéŸ³å£°èªè­˜ã®é–“é•ã„ãŒã‚ã‚Œã°ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚
- å…¨ä½“ã®æ„å‘³ã‚’å¤‰ãˆãªã„ç¯„å›²ã§ã€èª­ã¿ã‚„ã™ã„ã‚ˆã†ã«å¥èª­ç‚¹ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚

ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã€‘
${memo ? memo : 'ãªã—'}

ã€å…ƒã®æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã€‘
${rawTranscript}

ä»¥ä¸Šã®æŒ‡ç¤ºã«å¾“ã£ã¦ã€æ¸…æ›¸ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚`;

        const result = await model.generateContent(prompt);
        return result.response.text();
    } catch (error) {
        console.error("AIã«ã‚ˆã‚‹æ¸…æ›¸ä¸­ã«ã‚¨ãƒ©ãƒ¼:", error);
        throw error;
    }
}

// ç”ŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’WAVå½¢å¼ã«å¤‰æ›ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
const bufferToWav = (buffer: AudioBuffer): Blob => {
    const numOfChan = buffer.numberOfChannels;
    const len = buffer.length * numOfChan * 2 + 44;
    const bufferOut = new ArrayBuffer(len);
    const view = new DataView(bufferOut);
    let pos = 0;

    const writeString = (s: string) => { for (let i = 0; i < s.length; i++) { view.setUint8(pos++, s.charCodeAt(i)); } };
    const setUint16 = (data: number) => { view.setUint16(pos, data, true); pos += 2; };
    const setUint32 = (data: number) => { view.setUint32(pos, data, true); pos += 4; };

    writeString('RIFF'); setUint32(len - 8); writeString('WAVE');
    writeString('fmt '); setUint32(16); setUint16(1);
    setUint16(numOfChan); setUint32(buffer.sampleRate);
    setUint32(buffer.sampleRate * 2 * numOfChan); setUint16(numOfChan * 2);
    setUint16(16); writeString('data'); setUint32(len - pos - 4);

    const channels = [];
    for (let i = 0; i < numOfChan; i++) { channels.push(buffer.getChannelData(i)); }
    let offset = 0;
    while (pos < len) {
        for (let i = 0; i < numOfChan; i++) {
            let sample = Math.max(-1, Math.min(1, channels[i][offset]));
            sample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
            view.setInt16(pos, sample, true);
            pos += 2;
        }
        offset++;
    }
    return new Blob([view], { type: 'audio/wav' });
};


const formatTime = (seconds: number) => {
    const floorSeconds = Math.floor(seconds);
    const min = Math.floor(floorSeconds / 60);
    const sec = floorSeconds % 60;
    return `[${min.toString().padStart(2, '0')}:${sec.toString().padStart(2, '0')}]`;
};

const App: React.FC = () => {
    const [isRecording, setIsRecording] = useState(false);
    const [transcript, setTranscript] = useState<{ time: number, text: string }[]>([]);
    const [activeMicrophone, setActiveMicrophone] = useState<string>('ï¼ˆãƒã‚¤ã‚¯æœªç¢ºèªï¼‰');
    const [downloadLink, setDownloadLink] = useState<string>('');
    const [summary, setSummary] = useState<string>('');
    const [isLoadingAI, setIsLoadingAI] = useState<boolean>(false);
    const [copySuccess, setCopySuccess] = useState<string>('');
    const [memoText, setMemoText] = useState<string>('');
    const [activeTab, setActiveTab] = useState(0);
    const [showStopConfirm, setShowStopConfirm] = useState<boolean>(false);
    const [isDarkMode, setIsDarkMode] = useState(false);
    const [devices, setDevices] = useState<MediaDeviceInfo[]>([]);
    const [selectedMicId, setSelectedMicId] = useState<string>('');
    const [isTranscribing, setIsTranscribing] = useState<boolean>(false);
    const [loadingMessage, setLoadingMessage] = useState('é«˜ç²¾åº¦AIã®æº–å‚™ã‚’ã—ã¦ã„ã¾ã™...');
    const [isFileTranscriptComplete, setIsFileTranscriptComplete] = useState(false);
    const [modalInfo, setModalInfo] = useState<{ show: boolean, message: string }>({ show: false, message: '' });
    const [recoveryInfo, setRecoveryInfo] = useState<{ show: boolean, chunkCount: number }>({ show: false, chunkCount: 0 });

    const mediaRecorderRef = useRef<MediaRecorder | null>(null);
    const audioChunksRef = useRef<Blob[]>([]);
    const audioPlayerRef = useRef<HTMLAudioElement | null>(null);
    const canvasRef = useRef<HTMLCanvasElement | null>(null);
    const animationFrameIdRef = useRef<number | null>(null);
    const fileInputRef = useRef<HTMLInputElement | null>(null);
    const recordingStartTimeRef = useRef<number>(0);
    const lastTranscriptTextRef = useRef<string>('');
    const memoTextRef = useRef('');
    
    const audioContextRef = useRef<AudioContext | null>(null);
    const analyserRef = useRef<AnalyserNode | null>(null);
    const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null);

    useEffect(() => {
        const checkForCrashedData = async () => {
            try {
                const recoveredChunks = await dbManager.getAllAudioChunks();
                if (recoveredChunks.length > 0) {
                    setRecoveryInfo({ show: true, chunkCount: recoveredChunks.length });
                }
            } catch (error) {
                console.error("å¾©æ—§ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªä¸­ã«ã‚¨ãƒ©ãƒ¼:", error);
            }
        };

        getAudioDevices();
        checkForCrashedData();
        setLoadingMessage('AIæº–å‚™å®Œäº†');
    }, []);
    
    const getAudioDevices = async () => {
        try {
            await navigator.mediaDevices.getUserMedia({ audio: true });
            const audioDevices = (await navigator.mediaDevices.enumerateDevices()).filter(
                (device) => device.kind === 'audioinput'
            );
            setDevices(audioDevices);
            if (audioDevices.length > 0 && !selectedMicId) {
                setSelectedMicId(audioDevices[0].deviceId);
            }
        } catch (err) {
            console.error('ãƒã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ:', err);
        }
    };

    const handleDownload = (content: string, filename: string) => {
        if (!content) return;
        const blob = new Blob([content], { type: 'text/plain;charset=utf-8' });
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        a.download = filename;
        document.body.appendChild(a);
        a.click();
        document.body.removeChild(a);
        URL.revokeObjectURL(url);
    };

    const handleCopyToClipboard = () => {
        if (!summary) return;
        navigator.clipboard.writeText(summary).then(() => {
            setCopySuccess('ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸï¼');
            setTimeout(() => setCopySuccess(''), 2000);
        });
    };

    const stopVisualizer = () => {
        if(animationFrameIdRef.current) {
            cancelAnimationFrame(animationFrameIdRef.current);
        }
        if(audioContextRef.current && audioContextRef.current.state !== 'closed') {
            audioContextRef.current.close();
        }
        if (canvasRef.current) {
            const canvasCtx = canvasRef.current.getContext('2d');
            canvasCtx?.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);
        }
    };
    
    const setupVisualizer = (stream: MediaStream) => {
        const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
        const analyser = audioContext.createAnalyser();
        const source = audioContext.createMediaStreamSource(stream);
        source.connect(analyser);
        
        audioContextRef.current = audioContext;
        analyserRef.current = analyser;
        sourceRef.current = source;

        analyser.fftSize = 256;
        const bufferLength = analyser.frequencyBinCount;
        const dataArray = new Uint8Array(bufferLength);
        const canvas = canvasRef.current;
        if (!canvas) return;
        const canvasCtx = canvas.getContext('2d');

        const draw = () => {
            animationFrameIdRef.current = requestAnimationFrame(draw);
            if (!analyserRef.current || !canvasCtx) return;

            analyserRef.current.getByteFrequencyData(dataArray);

            canvasCtx.fillStyle = isDarkMode ? '#1e1e1e' : '#ffffff';
            canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

            const barWidth = (canvas.width / bufferLength) * 2.5;
            let barHeight;
            let x = 0;

            for (let i = 0; i < bufferLength; i++) {
                barHeight = dataArray[i];
                const r = 200 + (barHeight / 255) * 55;
                const g = 100;
                const b = 180 + (barHeight / 255) * 75;
                canvasCtx.fillStyle = `rgb(${r}, ${g}, ${b})`;
                canvasCtx.fillRect(x, canvas.height - barHeight / 1.5, barWidth, barHeight / 1.5);
                x += barWidth + 1;
            }
        };
        draw();
    };

    const toggleRecording = async () => {
        if (isRecording) {
            setShowStopConfirm(true);
        } else {
            try {
                await dbManager.clearAudioChunks();
                
                const constraints = { audio: { deviceId: selectedMicId ? { exact: selectedMicId } : undefined } };
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                
                setActiveMicrophone(devices.find(d => d.deviceId === selectedMicId)?.label || 'ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒã‚¤ã‚¯');
                setupVisualizer(stream);
                
                setDownloadLink('');
                audioChunksRef.current = [];
                lastTranscriptTextRef.current = '';
                setIsFileTranscriptComplete(false);
                mediaRecorderRef.current = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' });
                
                mediaRecorderRef.current.ondataavailable = async (e) => {
                    if (e.data.size > 0) {
                        audioChunksRef.current.push(e.data);
                        await dbManager.addAudioChunk(e.data);
                    }
                    
                    const fullAudioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm;codecs=opus' });
                    if (fullAudioBlob.size === 0) return;

                    setIsTranscribing(true);
                    try {
                        const wavBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' });
                        const fullTranscript = await transcribeAndIdentifySpeakers(wavBlob, memoTextRef.current);
                        const newText = fullTranscript.substring(lastTranscriptTextRef.current.length);

                        if(newText.trim().length > 0) {
                            const elapsedTime = (Date.now() - recordingStartTimeRef.current) / 1000;
                            setTranscript(prev => [...prev, { time: elapsedTime, text: newText }]);
                        }
                        
                        lastTranscriptTextRef.current = fullTranscript;

                    } catch (error) {
                        const elapsedTime = (Date.now() - recordingStartTimeRef.current) / 1000;
                        setTranscript(prev => [...prev, {time: elapsedTime, text: "[ã‚¨ãƒ©ãƒ¼]"}]);
                    } finally {
                        setIsTranscribing(false);
                    }
                };

                mediaRecorderRef.current.onstop = () => {
                    const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm;codecs=opus' });
                    setDownloadLink(URL.createObjectURL(audioBlob));
                    stream.getTracks().forEach(track => track.stop());
                    dbManager.clearAudioChunks();
                 };
                
                setTranscript([]);
                setSummary('');
                setActiveTab(0);
                setIsRecording(true);
                recordingStartTimeRef.current = Date.now();
                mediaRecorderRef.current.start(10000);

            } catch (err) {
                console.error("ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•—:", err);
                setActiveMicrophone('ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚');
            }
        }
    };
    
    const handleConfirmStop = () => {
        if (mediaRecorderRef.current?.state === "recording") {
            mediaRecorderRef.current.stop();
            dbManager.clearAudioChunks();
        }
        setIsRecording(false);
        stopVisualizer();
        setShowStopConfirm(false);
    };

    const handleFileChange = async (event: React.ChangeEvent<HTMLInputElement>) => {
        const file = event.target.files?.[0];
        if (!file) return;

        setTranscript([]);
        setSummary('');
        setDownloadLink(URL.createObjectURL(file));
        setActiveTab(0);
        setIsTranscribing(true);
        setIsFileTranscriptComplete(false);
        
        try {
            const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
            setLoadingMessage('éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æä¸­...');
            const arrayBuffer = await file.arrayBuffer();
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            
            const duration = audioBuffer.duration;
            const chunkSizeInSeconds = 60;
            let currentTime = 0;
            let chunkCount = 1;
            const totalChunks = Math.ceil(duration / chunkSizeInSeconds);

            while (currentTime < duration) {
                setLoadingMessage(`åˆæœŸæ–‡å­—èµ·ã“ã—ä¸­... (${chunkCount}/${totalChunks})`);
                const startTime = currentTime;
                const endTime = Math.min(currentTime + chunkSizeInSeconds, duration);
                const frameOffset = Math.floor(startTime * audioBuffer.sampleRate);
                const frameCount = Math.floor((endTime - startTime) * audioBuffer.sampleRate);
                const chunkBuffer = audioContext.createBuffer(audioBuffer.numberOfChannels, frameCount, audioBuffer.sampleRate);
                for (let i = 0; i < audioBuffer.numberOfChannels; i++) {
                    chunkBuffer.getChannelData(i).set(audioBuffer.getChannelData(i).subarray(frameOffset, frameOffset + frameCount));
                }
                const wavChunkBlob = bufferToWav(chunkBuffer);
                const transcribedText = await transcribeFileRaw(wavChunkBlob);
                setTranscript(prev => [...prev, {time: startTime, text: transcribedText}]);
                
                currentTime += chunkSizeInSeconds;
                chunkCount++;
                
                if(currentTime < duration) {
                    await new Promise(resolve => setTimeout(resolve, 5000));
                }
            }
            setIsFileTranscriptComplete(true);
            setModalInfo({ show: true, message: 'ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®åˆæœŸæ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ã€ŒAIã§æ¸…æ›¸ã™ã‚‹ã€ãƒœã‚¿ãƒ³ã§ã€ãƒ¡ãƒ¢ã®å†…å®¹ã‚’åæ˜ ã—ãŸæ¸…æ›¸ãŒã§ãã¾ã™ã€‚'});
        } catch (error) {
            console.error("ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼:", error);
            setModalInfo({ show: true, message: 'ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãŠä½¿ã„ã®ãƒ–ãƒ©ã‚¦ã‚¶ãŒå¯¾å¿œã—ã¦ã„ãªã„éŸ³å£°å½¢å¼ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚'});
        } finally {
            setIsTranscribing(false);
            setLoadingMessage('AIæº–å‚™å®Œäº†');
        }
    };

    const handleRefineTranscript = async () => {
        if(transcript.length === 0) {
            setModalInfo({ show: true, message: 'æ¸…æ›¸ã™ã‚‹æ–‡å­—èµ·ã“ã—ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚'});
            return;
        }
        setIsTranscribing(true);
        setLoadingMessage('AIãŒæ¸…æ›¸ä¸­ã§ã™...');
        try {
            const rawTranscript = transcript.map(t => t.text).join('\n');
            const refinedText = await refineTranscriptWithMemo(rawTranscript, memoText);
            
            const refinedLines = refinedText.split('\n').filter(line => line.trim() !== '');
            const originalTranscript = [...transcript];

            const newTranscript = refinedLines.map((line, index) => {
                const time = originalTranscript[index] ? originalTranscript[index].time : (originalTranscript[originalTranscript.length - 1]?.time || 0);
                return { time: time, text: line };
            });

            setTranscript(newTranscript);
            setModalInfo({ show: true, message: 'AIã«ã‚ˆã‚‹æ¸…æ›¸ãŒå®Œäº†ã—ã¾ã—ãŸã€‚'});
        } catch (error) {
            setModalInfo({ show: true, message: 'AIã«ã‚ˆã‚‹æ¸…æ›¸ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚'});
        } finally {
            setIsTranscribing(false);
            setLoadingMessage('AIæº–å‚™å®Œäº†');
            setIsFileTranscriptComplete(false);
        }
    };
    
    const handleProcessRecoveredData = async () => {
        setRecoveryInfo({ show: false, chunkCount: 0 });
        setIsTranscribing(true);
        setLoadingMessage('å¾©æ—§ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­...');
        try {
            const recoveredChunks = await dbManager.getAllAudioChunks();
            const recoveredBlob = new Blob(recoveredChunks, { type: 'audio/webm;codecs=opus' });
            setDownloadLink(URL.createObjectURL(recoveredBlob));
            
            const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
            const arrayBuffer = await recoveredBlob.arrayBuffer();
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            
            const duration = audioBuffer.duration;
            const chunkSizeInSeconds = 60;
            let currentTime = 0;
            let chunkCount = 1;
            const totalChunks = Math.ceil(duration / chunkSizeInSeconds);

            while (currentTime < duration) {
                setLoadingMessage(`å¾©æ—§ãƒ‡ãƒ¼ã‚¿ã‚’æ–‡å­—èµ·ã“ã—ä¸­... (${chunkCount}/${totalChunks})`);
                const startTime = currentTime;
                const endTime = Math.min(currentTime + chunkSizeInSeconds, duration);
                const frameOffset = Math.floor(startTime * audioBuffer.sampleRate);
                const frameCount = Math.floor((endTime - startTime) * audioBuffer.sampleRate);
                const chunkBuffer = audioContext.createBuffer(audioBuffer.numberOfChannels, frameCount, audioBuffer.sampleRate);
                for (let i = 0; i < audioBuffer.numberOfChannels; i++) {
                    chunkBuffer.getChannelData(i).set(audioBuffer.getChannelData(i).subarray(frameOffset, frameOffset + frameCount));
                }
                const wavChunkBlob = bufferToWav(chunkBuffer);
                const transcribedText = await transcribeFileRaw(wavChunkBlob);
                setTranscript(prev => [...prev, {time: currentTime, text: transcribedText}]);
                currentTime += chunkSizeInSeconds;
                chunkCount++;
            }

            setIsFileTranscriptComplete(true);
            setModalInfo({ show: true, message: 'å¾©æ—§ã—ãŸãƒ‡ãƒ¼ã‚¿ã®æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸã€‚'});

        } catch (error) {
            console.error("å¾©æ—§ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼:", error);
            setModalInfo({ show: true, message: 'å¾©æ—§ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚'});
        } finally {
            setIsTranscribing(false);
            setLoadingMessage('AIæº–å‚™å®Œäº†');
            dbManager.clearAudioChunks();
        }
    };


    const handleTimestampClick = (time: number) => { 
        if(audioPlayerRef.current) {
            audioPlayerRef.current.currentTime = time;
            audioPlayerRef.current.play();
        }
    };
    
    const generateSummary = async () => {
        const plainTranscript = transcript.map(item => `${formatTime(item.time)} ${item.text}`).join('\n\n');
        if (!plainTranscript && !memoText) {
            setModalInfo({ show: true, message: 'è¦ç´„ã™ã‚‹æ–‡å­—èµ·ã“ã—ã‚„ãƒ¡ãƒ¢ãŒã‚ã‚Šã¾ã›ã‚“ã€‚'});
            return;
        }
        setIsLoadingAI(true);
        setSummary('');
        setActiveTab(1);
        try {
            setModalInfo({ show: true, message: 'AIã«ã‚ˆã‚‹è­°äº‹éŒ²ã®ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™...'});
            const meetingDate = new Date().toLocaleString('ja-JP', { year: 'numeric', month: 'long', day: 'numeric', hour: '2-digit', minute: '2-digit' });
            const prompt = `ã‚ãªãŸã¯ãƒ—ãƒ­ã®è­°äº‹éŒ²ä½œæˆAIã§ã™ã€‚æä¾›ã•ã‚ŒãŸä»¥ä¸‹ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã€ä¼šè­°ã®æ–‡å­—èµ·ã“ã—ã€‘ã¨ã€æ‰‹å‹•ãƒ¡ãƒ¢ã€‘ã‚’åˆ†æã—ã€ãã®å†…å®¹ã‹ã‚‰ç¶²ç¾…çš„ã‹ã¤ç°¡æ½”ãªè­°äº‹éŒ²ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚è­°äº‹éŒ²ã¯ä»¥ä¸‹ã®æ§‹é€ ã¨ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚---## è­°äº‹éŒ²### 1. ä¼šè­°æ¦‚è¦**ä¼šè­°æ—¥æ™‚**: ${meetingDate}ä¼šè­°ã®ç›®çš„ã€ä¸»è¦ãªè­°é¡Œã€ãŠã‚ˆã³å…¨ä½“çš„ãªçµè«–ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã‚‹ã€‚### 2. è­°è«–ã®è¦ç‚¹ä¼šè­°ã§è©±ã—åˆã‚ã‚ŒãŸé‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚„è«–ç‚¹ã‚’ã€ä¸»è¦ãªãƒ†ãƒ¼ãƒã”ã¨ã«æ•´ç†ã—ã¦ç®‡æ¡æ›¸ãã§è¨˜è¿°ã™ã‚‹ã€‚ç™ºè¨€è€…åãŒç‰¹å®šã§ãã‚‹å ´åˆã¯ã€å¯èƒ½ã§ã‚ã‚Œã°ã€Œ[ç™ºè¨€è€…å]ï¼š[ç™ºè¨€å†…å®¹ã®è¦ç´„]ã€ã®ã‚ˆã†ã«è¨˜è¼‰ã™ã‚‹ã€‚è¤‡æ•°ã®è­°é¡ŒãŒã‚ã£ãŸå ´åˆã¯ã€è­°é¡Œã”ã¨ã«ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’åˆ†ã‘ã‚‹ã“ã¨ã‚’æ¤œè¨ã™ã‚‹ã€‚### 3. æ±ºå®šäº‹é …ä¼šè­°ã§åˆæ„ã•ã‚ŒãŸäº‹é …ã‚„çµè«–ã‚’æ˜ç¢ºã«ç®‡æ¡æ›¸ãã§è¨˜è¿°ã™ã‚‹ã€‚æ±ºå®šäº‹é …ãŒè¤‡æ•°ã‚ã‚‹å ´åˆã¯ã€å„ªå…ˆé †ä½ã‚„é–¢é€£æ€§ã«å¿œã˜ã¦æ•´ç†ã™ã‚‹ã€‚### 4. ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ  (æ¬¡å›ä»¥é™ã®ã‚¿ã‚¹ã‚¯)ä¼šè­°ã§æ±ºå®šã•ã‚ŒãŸå…·ä½“çš„ãªè¡Œå‹•ã‚„ã‚¿ã‚¹ã‚¯ã€æ‹…å½“è€…ã€æœŸé™ã‚’ç®‡æ¡æ›¸ãã§è¨˜è¿°ã™ã‚‹ã€‚- **ã‚¿ã‚¹ã‚¯å†…å®¹**:- **æ‹…å½“è€…**:- **æœŸé™**:- **å‚™è€ƒ**: ï¼ˆã‚ã‚Œã°ï¼‰### 5. æ¬¡å›é–‹å‚¬ã«ã¤ã„ã¦ (ã‚‚ã—è¨€åŠãŒã‚ã‚Œã°)æ¬¡å›ä¼šè­°ã®æ—¥ç¨‹ã€æ™‚é–“ã€å ´æ‰€ã€ä¸»è¦è­°é¡Œãªã©ã€æ¬¡å›é–‹å‚¬ã«é–¢ã™ã‚‹æƒ…å ±ãŒã‚ã‚Œã°è¨˜è¿°ã™ã‚‹ã€‚---**ã€è­°äº‹éŒ²ä½œæˆã®éš›ã®æ³¨æ„äº‹é …ã€‘** * **ç¶²ç¾…æ€§:** ä¼šè­°ã®å…¨ã¦ã®é‡è¦ãªæƒ…å ±ã‚’æ¼ã‚Œãªãå«ã‚ã‚‹ã“ã¨ã€‚* **ç°¡æ½”æ€§:** ç„¡é§„ãªè¡¨ç¾ã‚’çœãã€è¦ç‚¹ã‚’åˆ†ã‹ã‚Šã‚„ã™ãã¾ã¨ã‚ã‚‹ã“ã¨ã€‚å†—é•·ãªä¼šè©±ã¯è¦ç´„ã—ã€çµè«–ã‚’æ˜ç¢ºã«ã™ã‚‹ã“ã¨ã€‚* **å®¢è¦³æ€§:** å€‹äººçš„ãªæ„è¦‹ã‚„æ„Ÿæƒ…ã‚’äº¤ãˆãšã€ä¼šè­°ã§è©±ã•ã‚ŒãŸäº‹å®Ÿã®ã¿ã‚’è¨˜è¿°ã™ã‚‹ã“ã¨ã€‚* **æ­£ç¢ºæ€§:** å›ºæœ‰åè©ã€æ•°å€¤ã€æ±ºå®šäº‹é …ãªã©ã¯å¯èƒ½ãªé™ã‚Šæ­£ç¢ºã«è¨˜è¿°ã™ã‚‹ã“ã¨ã€‚* **è¨€è‘‰é£ã„:** ä¸å¯§ã‹ã¤ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªãƒˆãƒ¼ãƒ³ã§è¨˜è¿°ã™ã‚‹ã“ã¨ã€‚* **ãƒã‚¤ã‚ºã®æ’é™¤:** éŸ³å£°èªè­˜ã®ãƒã‚¤ã‚ºã‚„ã€æœ¬é¡Œã¨é–¢ä¿‚ã®ãªã„é›‘è«‡ã¯è­°äº‹éŒ²ã‹ã‚‰é™¤å¤–ã™ã‚‹ã“ã¨ã€‚* **ä¸æ˜ç­ãªç‚¹ã®æ‰±ã„:** ã‚‚ã—å†…å®¹ãŒä¸æ˜ç­ãªç‚¹ã‚„ã€ç™ºè¨€ãŒé€”åˆ‡ã‚Œã¦ã„ã‚‹ç®‡æ‰€ãŒã‚ã‚Œã°ã€ãã®æ—¨ã‚’ç°¡æ½”ã«è¨˜è¼‰ã™ã‚‹ã‹ã€æ–‡è„ˆã‹ã‚‰åˆ¤æ–­ã—ã¦è£œå®Œã™ã‚‹ã“ã¨ã€‚ãŸã ã—ã€æ¨æ¸¬ãŒéãã‚‹å ´åˆã¯ã€Œ[å†…å®¹ä¸æ˜]ã€ã®ã‚ˆã†ã«è¨˜ã™ã“ã¨ã‚‚è€ƒæ…®ã™ã‚‹ã€‚---ãã‚Œã§ã¯ã€ä»¥ä¸‹ã®æƒ…å ±ã‹ã‚‰è­°äº‹éŒ²ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚ã€ä¼šè­°ã®æ–‡å­—èµ·ã“ã—ã€‘${plainTranscript}ã€æ‰‹å‹•ãƒ¡ãƒ¢ã€‘${memoText}`;
            const result = await model.generateContent(prompt);
            setSummary(result.response.text());
            setModalInfo({ show: true, message: 'è­°äº‹éŒ²ãŒå®Œæˆã—ã¾ã—ãŸï¼ã€ŒAIã«ã‚ˆã‚‹è­°äº‹éŒ²ã€ã‚¿ãƒ–ã§ã”ç¢ºèªãã ã•ã„ã€‚'});
        } catch (error) {
            console.error("AIã«ã‚ˆã‚‹è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:", error);
            setModalInfo({ show: true, message: 'è­°äº‹éŒ²ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚'});
        } finally {
            setIsLoadingAI(false);
        }
    };
    
    const customStyles = `
        body { background-color: ${isDarkMode ? '#121212' : '#f4f7f9'}; color: ${isDarkMode ? '#e0e0e0' : '#333'}; transition: background-color 0.3s, color 0.3s; }
        .main-container { background-color: ${isDarkMode ? '#1e1e1e' : '#ffffff'}; padding: 20px 30px; font-family: sans-serif; max-width: 800px; margin: 20px auto; border-radius: 8px; box-shadow: ${isDarkMode ? '0 4px 20px rgba(0,0,0,0.5)' : '0 4px 20px rgba(0,0,0,0.1)'}; transition: background-color 0.3s, box-shadow 0.3s; }
        h1, h2 { color: ${isDarkMode ? '#ffffff' : '#000000'}; }
        .info-box { background-color: ${isDarkMode ? '#2a2a2a' : '#f0f0f0'}; border: 1px solid ${isDarkMode ? '#444' : '#ddd'}; color: ${isDarkMode ? '#e0e0e0' : '#333'}; }
        .react-tabs__tab { background: ${isDarkMode ? '#2a2a2a' : '#f0f0f0'}; border-color: ${isDarkMode ? '#444' : '#ddd'}; color: ${isDarkMode ? '#a0a0a0' : '#333'}; border-bottom: none; }
        .react-tabs__tab--selected { background: ${isDarkMode ? '#1e1e1e' : '#ffffff'}; color: ${isDarkMode ? 'white' : '#007bff'}; border-color: ${isDarkMode ? '#444' : '#ddd'}; border-bottom: 1px solid ${isDarkMode ? '#1e1e1e' : '#ffffff'}; position: relative; top: 1px; }
        .react-tabs__tab-panel--selected { border: 1px solid ${isDarkMode ? '#444' : '#ddd'}; padding: 15px; background-color: ${isDarkMode ? '#2a2a2a' : '#ffffff'}; }
        .transcript-panel { background-color: ${isDarkMode ? '#2a2a2a' : '#fdfdfd'}; border: 1px solid ${isDarkMode ? '#444' : '#ccc'}; white-space: pre-wrap; }
        textarea { background-color: ${isDarkMode ? '#333' : '#fff'}; color: ${isDarkMode ? '#e0e0e0' : '#000'}; border-color: ${isDarkMode ? '#555' : '#ccc'}; }
        .ai-summary-panel { background-color: #1e1e1e; color: #d4d4d4; padding: 25px; border-radius: 8px; border: 1px solid #333; min-height: 250px; white-space: pre-wrap; line-height: 1.7; }
        .ai-summary-panel h2, .ai-summary-panel h3 { color: #ffffff; }
        .ai-summary-panel strong { color: #569cd6; }
        .toggle-switch { display: flex; flex-direction: column; align-items: center; gap: 4px; }
        .switch { position: relative; display: inline-block; width: 50px; height: 26px; }
        .switch input { opacity: 0; width: 0; height: 0; }
        .slider { position: absolute; cursor: pointer; top: 0; left: 0; right: 0; bottom: 0; background-color: #ccc; transition: .4s; border-radius: 34px; }
        .slider:before { position: absolute; content: ""; height: 20px; width: 20px; left: 3px; bottom: 3px; background-color: white; transition: .4s; border-radius: 50%; }
        input:checked + .slider { background-color: #2196F3; }
        input:checked + .slider:before { transform: translateX(24px); }
        select { padding: 8px; border-radius: 5px; border: 1px solid ${isDarkMode ? '#444' : '#ddd'}; background-color: ${isDarkMode ? '#2a2a2a' : '#f0f0f0'}; color: ${isDarkMode ? '#e0e0e0' : '#333'}; }
        .timestamp { color: #ff69b4; cursor: pointer; font-weight: bold; margin-right: 10px; }
        .timestamp:hover { text-decoration: underline; }
        audio { filter: ${isDarkMode ? 'invert(1) contrast(0.8) brightness(1.2)' : 'none'}; }
    `;

    return (
        <>
            <style>{customStyles}</style>
            <div className="main-container">
                <div style={{ display: 'flex', alignItems: 'center', justifyContent: 'space-between', marginBottom: '20px' }}>
                    <div style={{ display: 'flex', alignItems: 'center', gap: '10px' }}>
                        <svg xmlns="http://www.w3.org/2000/svg" width="28" height="28" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path><path d="M19 10v2a7 7 0 0 1-14 0v-2"></path><line x1="12" y1="19" x2="12" y2="22"></line></svg>
                        <h1 style={{ fontSize: '1.8em', margin: 0 }}>AIè­°äº‹éŒ²ãƒ„ãƒ¼ãƒ«</h1>
                    </div>
                    <div className="toggle-switch">
                        <span style={{ fontSize: '12px', color: isDarkMode ? '#aaa' : '#555' }}>ãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰</span>
                        <label className="switch">
                            <input type="checkbox" checked={isDarkMode} onChange={() => setIsDarkMode(!isDarkMode)} />
                            <span className="slider"></span>
                        </label>
                    </div>
                </div>

                <p style={{marginTop: 0}}>ãã®å ´ã§éŒ²éŸ³ã™ã‚‹ã‹ã€æ—¢å­˜ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚</p>
                <div style={{display: 'flex', gap: '10px'}}>
                    <button onClick={toggleRecording} disabled={loadingMessage !== 'AIæº–å‚™å®Œäº†'} style={{ fontSize: '16px', padding: '10px 20px', backgroundColor: isRecording ? '#dc3545' : '#007bff', color: 'white', border: 'none', borderRadius: '5px', cursor: 'pointer', flex: 1 }}>
                        {isRecording ? 'â–  éŒ²éŸ³åœæ­¢' : (loadingMessage !== 'AIæº–å‚™å®Œäº†' ? loadingMessage : 'â— éŒ²éŸ³é–‹å§‹')}
                    </button>
                    <input type="file" ref={fileInputRef} onChange={handleFileChange} accept=".mp3,.m4a,.wav" style={{ display: 'none' }} />
                    <button onClick={() => fileInputRef.current?.click()} disabled={(loadingMessage !== 'AIæº–å‚™å®Œäº†') || isRecording} style={{ fontSize: '16px', padding: '10px 20px', backgroundColor: '#6c757d', color: 'white', border: 'none', borderRadius: '5px', cursor: 'pointer', flex: 1 }}>
                        éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
                    </button>
                </div>
                
                <canvas ref={canvasRef} style={{ width: '100%', height: '60px', marginTop: '15px', borderRadius: '5px', display: isRecording ? 'block' : 'none' }}></canvas>
                
                <div className="info-box" style={{ marginTop: '15px', padding: '15px', borderRadius: '5px' }}>
                     <label htmlFor="mic-select" style={{display: 'block', marginBottom: '8px'}}><strong>ä½¿ç”¨ã™ã‚‹ãƒã‚¤ã‚¯ã‚’é¸æŠ</strong></label>
                     <select id="mic-select" value={selectedMicId} onChange={(e) => setSelectedMicId(e.target.value)} disabled={isRecording} style={{width: '100%'}}>
                         {devices.length === 0 && <option>ãƒã‚¤ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“</option>}
                         {devices.map(device => ( <option key={device.deviceId} value={device.deviceId}> {device.label || `ãƒã‚¤ã‚¯ ${devices.indexOf(device) + 1}`} </option> ))}
                     </select>
                </div>

                <div style={{ margin: '20px 0', textAlign: 'center' }}>
                    <button onClick={generateSummary} disabled={isLoadingAI || transcript.length === 0} style={{ fontSize: '16px', padding: '12px 24px', backgroundColor: isLoadingAI || transcript.length === 0 ? '#6c757d' : '#17a2b8', color: 'white', border: 'none', borderRadius: '5px', cursor: 'pointer', transition: 'background-color 0.3s' }}>
                        {isLoadingAI ? 'AIãŒè€ƒãˆä¸­...' : 'ğŸ¤– AIã§è­°äº‹éŒ²ã‚’ä½œæˆ'}
                    </button>
                </div>

                <Tabs selectedIndex={activeTab} onSelect={index => setActiveTab(index)} style={{marginTop: '20px'}}>
                    <TabList>
                        <Tab>æ–‡å­—èµ·ã“ã—</Tab>
                        <Tab>AIã«ã‚ˆã‚‹è­°äº‹éŒ²</Tab>
                        <Tab>æ‰‹å‹•ãƒ¡ãƒ¢</Tab>
                    </TabList>

                    <TabPanel>
                        {downloadLink && !isTranscribing && ( <div style={{ margin: '15px 0' }}> <p style={{fontWeight: 'bold', marginBottom: '5px'}}>éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å†ç”Ÿ</p> <audio ref={audioPlayerRef} src={downloadLink} controls style={{width: '100%'}} /> <a href={downloadLink} download={`recording-${new Date().toISOString().slice(0,10)}.webm`} style={{fontSize: '12px', display: 'block', textAlign: 'right', marginTop: '5px'}}>ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a> </div> )}
                        
                        <div style={{display: 'flex', justifyContent: 'space-between', alignItems: 'center', flexWrap: 'wrap', marginBottom: '10px'}}>
                            <h2 style={{ marginTop: '10px', marginBottom: '10px' }}>æ–‡å­—èµ·ã“ã—çµæœ</h2>
                            {!isRecording && transcript.length > 0 && !isTranscribing && (
                                <button onClick={handleRefineTranscript} style={{fontSize: '14px', padding: '8px 16px', backgroundColor: '#28a745', color: 'white', border: 'none', borderRadius: '5px', cursor: 'pointer' }}>
                                    AIã§æ¸…æ›¸ã™ã‚‹
                                </button>
                            )}
                            <button onClick={() => handleDownload(transcript.map(t => `${formatTime(t.time)} ${t.text}`).join('\n\n'), `transcript-${new Date().toISOString().slice(0, 10)}.txt`)} disabled={transcript.length === 0} style={{fontSize: '14px', padding: '8px 16px', backgroundColor: transcript.length === 0 ? '#6c757d' : '#6f42c1', color: 'white', border: 'none', borderRadius: '5px', cursor: 'pointer' }}>
                                åŸæ–‡ã‚’ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                            </button>
                        </div>
                        <div className="transcript-panel" style={{ padding: '10px', minHeight: '200px', lineHeight: '1.8' }}>
                            {transcript.length > 0 ? (
                                transcript.map((item, index) => (
                                    <p key={index} style={{margin: '0 0 10px 0'}}>
                                        <span className="timestamp" onClick={() => handleTimestampClick(item.time)}> {formatTime(item.time)} </span>
                                        {item.text}
                                    </p>
                                ))
                            ) : (
                                <p>{isTranscribing ? '' : 'ã“ã“ã«é«˜ç²¾åº¦AIã«ã‚ˆã‚‹æ–‡å­—èµ·ã“ã—çµæœãŒãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡¨ç¤ºã•ã‚Œã¾ã™...'}</p>
                            )}
                            {isRecording && isTranscribing && ( <p style={{margin: '0 0 10px 0', color: '#888'}}> <span className="timestamp">{formatTime((Date.now() - recordingStartTimeRef.current)/1000)}</span> ï¼ˆAIãŒè€ƒãˆã¦ã„ã¾ã™...ï¼‰ </p> )}
                            {!isRecording && isTranscribing && ( <p style={{margin: '0 0 10px 0', color: '#888'}}> {loadingMessage} </p> )}
                        </div>
                    </TabPanel>
                    
                    <TabPanel>
                        <div style={{display: 'flex', justifyContent: 'space-between', alignItems: 'center', flexWrap: 'wrap', marginBottom: '15px'}}>
                            <h2 style={{ marginTop: '10px', marginBottom: '10px' }}>AIã«ã‚ˆã‚‹è­°äº‹éŒ²</h2>
                            <div style={{ display: 'flex', gap: '10px', alignItems: 'center' }}>
                                <button onClick={() => handleDownload(summary, `minutes-${new Date().toISOString().slice(0, 10)}.txt`)} disabled={!summary} style={{fontSize: '14px', padding: '8px 16px', backgroundColor: !summary ? '#6c757d' : '#0069d9', color: 'white', border: 'none', borderRadius: '5px', cursor: 'pointer' }}> è­°äº‹éŒ²ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ </button>
                                <button onClick={handleCopyToClipboard} disabled={!summary} style={{fontSize: '14px', padding: '8px 16px', backgroundColor: !summary ? '#6c757d' : '#5a6268', color: 'white', border: 'none', borderRadius: '5px', cursor: 'pointer' }}> è­°äº‹éŒ²ã‚’ã‚³ãƒ”ãƒ¼ </button>
                                {copySuccess && <span style={{color: 'green', fontSize: '14px'}}>{copySuccess}</span>}
                            </div>
                        </div>
                        <div className="ai-summary-panel">
                            {summary ? <ReactMarkdown>{summary}</ReactMarkdown> : <p>ã“ã“ã«AIãŒç”Ÿæˆã—ãŸè­°äº‹éŒ²ãŒè¡¨ç¤ºã•ã‚Œã¾ã™...</p>}
                        </div>
                    </TabPanel>

                    <TabPanel>
                        <h2 style={{ marginTop: '10px' }}>æ‰‹å‹•ãƒ¡ãƒ¢</h2>
                        <textarea
                            value={memoText}
                            onChange={(e) => {
                                setMemoText(e.target.value);
                                memoTextRef.current = e.target.value;
                            }}
                            placeholder="ä¼šè­°ã®å‚åŠ è€…ã€æ±ºå®šäº‹é …ã®èƒŒæ™¯ã€æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãªã©ã€éŸ³å£°ä»¥å¤–ã®æƒ…å ±ã‚’ã“ã“ã«ãƒ¡ãƒ¢ã—ã¾ã™ã€‚ä¾‹ï¼šå‚åŠ è€…ï¼šå±±ç”°å¤ªéƒã€ä½è—¤èŠ±å­"
                            style={{ width: '98%', minHeight: '250px', padding: '10px', border: '1px solid', borderRadius: '5px', fontSize: '16px', lineHeight: '1.6' }}
                        />
                    </TabPanel>
                </Tabs>
            </div>

            {modalInfo.show && (
                <div style={{ position: 'fixed', top: 0, left: 0, width: '100%', height: '100%', backgroundColor: 'rgba(0, 0, 0, 0.5)', display: 'flex', justifyContent: 'center', alignItems: 'center', zIndex: 1000 }}>
                    <div style={{ backgroundColor: isDarkMode ? '#2a2a2a' : 'white', color: isDarkMode ? '#e0e0e0' : '#333', padding: '25px 30px', borderRadius: '8px', boxShadow: '0 4px 15px rgba(0,0,0,0.2)', textAlign: 'center', width: '90%', maxWidth: '400px' }}>
                        <p style={{margin: '0 0 20px', fontSize: '1.1em', lineHeight: '1.6'}}>{modalInfo.message}</p>
                        <button onClick={() => setModalInfo({ show: false, message: '' })} style={{fontSize: '15px', padding: '10px 25px', backgroundColor: '#007bff', color: 'white', border: 'none', borderRadius: '5px', cursor: 'pointer'}} >
                            é–‰ã˜ã‚‹
                        </button>
                    </div>
                </div>
            )}
            
            {recoveryInfo.show && (
                <div style={{ position: 'fixed', top: 0, left: 0, width: '100%', height: '100%', backgroundColor: 'rgba(0, 0, 0, 0.6)', display: 'flex', justifyContent: 'center', alignItems: 'center', zIndex: 1001 }}>
                    <div style={{ backgroundColor: isDarkMode ? '#2a2a2a' : 'white', color: isDarkMode ? '#e0e0e0' : '#333', padding: '25px', borderRadius: '8px', boxShadow: '0 4px 15px rgba(0,0,0,0.2)', textAlign: 'center', width: '90%', maxWidth: '420px' }}>
                        <h3 style={{marginTop: 0, fontSize: '1.3em', color: '#ffc107'}}>âš  æœªä¿å­˜ã®éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿</h3>
                        <p style={{margin: '15px 0 25px', fontSize: '0.95em'}}>å‰å›ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒæ­£å¸¸ã«çµ‚äº†ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚é€”ä¸­ã¾ã§éŒ²éŸ³ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸãŒã€ã©ã†ã—ã¾ã™ã‹ï¼Ÿ</p>
                        <div style={{display: 'flex', justifyContent: 'center', gap: '15px'}}>
                            <button onClick={handleProcessRecoveredData} style={{fontSize: '15px', padding: '10px 20px', backgroundColor: '#28a745', color: 'white', border: 'none', borderRadius: '5px', cursor: 'pointer', minWidth: '120px'}}>
                                æ–‡å­—èµ·ã“ã—ã™ã‚‹
                            </button>
                            <button onClick={() => { dbManager.clearAudioChunks(); setRecoveryInfo({ show: false, chunkCount: 0 }); }} style={{fontSize: '15px', padding: '10px 20px', backgroundColor: '#6c757d', color: 'white', border: 'none', borderRadius: '5px', cursor: 'pointer', minWidth: '120px'}}>
                                ãƒ‡ãƒ¼ã‚¿ã‚’ç ´æ£„
                            </button>
                        </div>
                    </div>
                </div>
            )}

            {showStopConfirm && (
                <div style={{ position: 'fixed', top: 0, left: 0, width: '100%', height: '100%', backgroundColor: 'rgba(0, 0, 0, 0.6)', display: 'flex', justifyContent: 'center', alignItems: 'center', zIndex: 1000 }}>
                    <div style={{ backgroundColor: isDarkMode ? '#2a2a2a' : 'white', color: isDarkMode ? '#e0e0e0' : '#333', padding: '25px', borderRadius: '8px', boxShadow: '0 4px 15px rgba(0,0,0,0.2)', textAlign: 'center', width: '90%', maxWidth: '360px' }}>
                        <h3 style={{marginTop: 0, fontSize: '1.3em', color: isDarkMode ? '#ffffff' : '#000000'}}>éŒ²éŸ³ã‚’çµ‚äº†ã—ã¾ã™ã‹ï¼Ÿ</h3>
                        <p style={{margin: '15px 0 25px', fontSize: '0.95em'}}>éŒ²éŸ³ã‚’çµ‚äº†ã—ã€è­°äº‹éŒ²ã®ä½œæˆæº–å‚™ã‚’é–‹å§‹ã—ã¾ã™ã€‚</p>
                        <div style={{display: 'flex', justifyContent: 'center', gap: '15px'}}>
                            <button onClick={handleConfirmStop} style={{fontSize: '15px', padding: '10px 20px', backgroundColor: '#dc3545', color: 'white', border: 'none', borderRadius: '5px', cursor: 'pointer', minWidth: '110px'}}>
                                ã¯ã„ã€çµ‚äº†ã™ã‚‹
                            </button>
                            <button onClick={() => setShowStopConfirm(false)} style={{fontSize: '15px', padding: '10px 20px', backgroundColor: '#6c757d', color: 'white', border: 'none', borderRadius: '5px', cursor: 'pointer', minWidth: '110px'}}>
                                ã‚­ãƒ£ãƒ³ã‚»ãƒ«
                            </button>
                        </div>
                    </div>
                </div>
            )}
        </>
    );
};

export default App;